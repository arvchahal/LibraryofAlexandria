{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chaha\\AppData\\Local\\Temp\\ipykernel_32568\\984645584.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16559it [00:00, 50947.62it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(\"./info/booksummaries.txt\", 'r') as f:\n",
    "  reader = csv.reader(f, dialect='excel-tab')\n",
    "  for row in tqdm(reader):\n",
    "    data.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16559/16559 [00:00<00:00, 1284272.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>book_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>{\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>{\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1756</td>\n",
       "      <td>An Enquiry Concerning Human Understanding</td>\n",
       "      <td></td>\n",
       "      <td>The argument of the Enquiry proceeds by a ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2080</td>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>{\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...</td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2152</td>\n",
       "      <td>All Quiet on the Western Front</td>\n",
       "      <td>{\"/m/098tmk\": \"War novel\", \"/m/016lj8\": \"Roman...</td>\n",
       "      <td>The book tells the story of Paul Bäumer, a Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2890</td>\n",
       "      <td>A Wizard of Earthsea</td>\n",
       "      <td>{\"/m/0dwly\": \"Children's literature\", \"/m/01hm...</td>\n",
       "      <td>Ged is a young boy on Gont, one of the larger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2950</td>\n",
       "      <td>Anyone Can Whistle</td>\n",
       "      <td></td>\n",
       "      <td>The story is set in an imaginary American tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4081</td>\n",
       "      <td>Blade Runner 3: Replicant Night</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/014dfn\": \"...</td>\n",
       "      <td>Living on Mars, Deckard is acting as a consul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4082</td>\n",
       "      <td>Blade Runner 2: The Edge of Human</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/014dfn\": \"...</td>\n",
       "      <td>Beginning several months after the events in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  book_id                                  book_name  \\\n",
       "0     620                                Animal Farm   \n",
       "1     843                         A Clockwork Orange   \n",
       "2     986                                 The Plague   \n",
       "3    1756  An Enquiry Concerning Human Understanding   \n",
       "4    2080                       A Fire Upon the Deep   \n",
       "5    2152             All Quiet on the Western Front   \n",
       "6    2890                       A Wizard of Earthsea   \n",
       "7    2950                         Anyone Can Whistle   \n",
       "8    4081            Blade Runner 3: Replicant Night   \n",
       "9    4082          Blade Runner 2: The Edge of Human   \n",
       "\n",
       "                                               genre  \\\n",
       "0  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
       "1  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
       "2  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
       "3                                                      \n",
       "4  {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
       "5  {\"/m/098tmk\": \"War novel\", \"/m/016lj8\": \"Roman...   \n",
       "6  {\"/m/0dwly\": \"Children's literature\", \"/m/01hm...   \n",
       "7                                                      \n",
       "8  {\"/m/06n90\": \"Science Fiction\", \"/m/014dfn\": \"...   \n",
       "9  {\"/m/06n90\": \"Science Fiction\", \"/m/014dfn\": \"...   \n",
       "\n",
       "                                             summary  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  \n",
       "1   Alex, a teenager living in near-future Englan...  \n",
       "2   The text of The Plague is divided into five p...  \n",
       "3   The argument of the Enquiry proceeds by a ser...  \n",
       "4   The novel posits that space around the Milky ...  \n",
       "5   The book tells the story of Paul Bäumer, a Ge...  \n",
       "6   Ged is a young boy on Gont, one of the larger...  \n",
       "7   The story is set in an imaginary American tow...  \n",
       "8   Living on Mars, Deckard is acting as a consul...  \n",
       "9   Beginning several months after the events in ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_id = []\n",
    "book_name = []\n",
    "summary = []\n",
    "genre = []\n",
    "# Iterate over the rows in the data\n",
    "\n",
    "for i in tqdm(data):\n",
    "  # Extract the information for each column and store it in the corresponding list\n",
    "    book_id.append(i[0])\n",
    "    book_name.append(i[2])\n",
    "    genre.append(i[5])\n",
    "    summary.append(i[6])\n",
    "\n",
    "# Create a Pandas DataFrame from the lists\n",
    "books = pd.DataFrame({'book_id': book_id, 'book_name': book_name,\n",
    "                       'genre': genre, 'summary': summary})\n",
    "books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\chaha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chaha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chaha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chaha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#preprocessing of the data and removing bad names and other werid info to get the bst results\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_word = set(stopwords.words('english'))\n",
    "\n",
    "def proc(inp):\n",
    "  inp = str(inp)\n",
    "  text = inp.lower()\n",
    "  text = re.sub(r'[^a-zA-Z]',\" \",text)\n",
    "\n",
    "  tokenized = nltk.word_tokenize(text)\n",
    "  tokens = [lemmatizer.lemmatize(word) for word in tokenized]\n",
    "  return \" \".join(tokens)\n",
    "\n",
    "def preprocess_dataframe(df, column_name):\n",
    "    df[column_name] = df[column_name].apply(proc)\n",
    "    return df\n",
    "\n",
    "#now preprocss each column\n",
    "\n",
    "books_clean = preprocess_dataframe(books, 'book_name')\n",
    "books_clean = preprocess_dataframe(books, 'genre')\n",
    "books_clean = preprocess_dataframe(books, 'summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_clean[\"book_info\"] = books_clean[\"summary\"] + \" \" + books_clean[\"genre\"] \n",
    "#deleting the summary and genre columns\n",
    "books_clean.drop(['summary','genre'],inplace=True, axis=1)\n",
    "#dropping the book id column\n",
    "books_clean.drop(['book_id'],inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.00867306 0.00708674 ... 0.00456184 0.00165874 0.00644459]\n",
      " [0.00867306 1.         0.01337266 ... 0.00480672 0.00265714 0.00822467]\n",
      " [0.00708674 0.01337266 1.         ... 0.00662154 0.00403892 0.01456101]\n",
      " ...\n",
      " [0.00456184 0.00480672 0.00662154 ... 1.         0.00257448 0.01060132]\n",
      " [0.00165874 0.00265714 0.00403892 ... 0.00257448 1.         0.00298281]\n",
      " [0.00644459 0.00822467 0.01456101 ... 0.01060132 0.00298281 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#vctorize the data and then compare the matricies to itself.\n",
    "\n",
    "#first vecotrize the words into numbers and then run the cosine similairty on the matrix agaisnt itself\n",
    "tf = TfidfVectorizer(analyzer = \"word\", ngram_range=(1,2), min_df=0.0, stop_words='english')\n",
    "\n",
    "tfidf_matrix = tf.fit_transform(books_clean['book_info'])\n",
    "\n",
    "cosine_sim =  cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(liked_books_indices, top_n=5):\n",
    "    avg_similarity = cosine_sim[liked_books_indices].mean(axis=0)\n",
    "    top_similar_indices = avg_similarity.argsort()[::-1][:top_n]\n",
    "    recommended_books = [(books_clean.index[idx], books_clean.iloc[idx]['book_info']) for idx in top_similar_indices]\n",
    "    recommended_books_filtered = []\n",
    "    for book_id, book_info in recommended_books:\n",
    "        if book_id not in liked_books_indices:\n",
    "            recommended_books_filtered.append((book_id, book_info))\n",
    "    \n",
    "    return recommended_books_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_name                                          animal farm\n",
      "book_info    old major the old boar on the manor farm call ...\n",
      "Name: 0, dtype: object\n",
      "book_name                                   a clockwork orange\n",
      "book_info    alex a teenager living in near future england ...\n",
      "Name: 1, dtype: object\n",
      "book_name                                           the plague\n",
      "book_info    the text of the plague is divided into five pa...\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "liked_books_indices = [0, 1, 2]  # Example book indices that the user has liked\n",
    "for i in liked_books_indices:\n",
    "    print(books_clean.iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_books = get_recommendations(liked_books_indices)\n",
    "print(recommended_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'userBooks': {'LfAJT0xxa4RKZs7DKTda2YiEUvA3': {'9781250129130': {'authors': 'S. Jae-Jones', 'description': \"Devoting herself to her musical career six months after the events of Wintersong, Liesl struggles with her brother's cold withdrawal and her own inability to forget the austere young man who inspired her efforts.\", 'image': 'http://books.google.com/books/content?id=rxJFDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api', 'infoLink': 'http://books.google.com/books?id=rxJFDwAAQBAJ&dq=isbn:9781250129130&hl=&source=gbs_api', 'isbn13': '9781250129130', 'publishedDate': '2018-02-06', 'title': 'Shadowsong'}}}}\n"
     ]
    }
   ],
   "source": [
    "with open('tst.json','r') as f:\n",
    "  r = json.load(f)\n",
    "print(r)\n",
    "r.user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        LfAJT0xxa4RKZs7DKTda2YiEUvA3  \\\n",
      "0  {'9781250129130': {'authors': 'S. Jae-Jones', ...   \n",
      "\n",
      "                        user_id       isbn  \n",
      "0  LfAJT0xxa4RKZs7DKTda2YiEUvA3  userBooks  \n"
     ]
    }
   ],
   "source": [
    "# Flatten the data\n",
    "rows = []\n",
    "for user_id, books in r['userBooks'].items():\n",
    "    for isbn, details in r.items():\n",
    "        row = details.copy()\n",
    "        row['user_id'] = user_id\n",
    "        row['isbn'] = isbn\n",
    "        rows.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\chaha\\anaconda3\\envs\\cs4262\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m first_book_title \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chaha\\anaconda3\\envs\\cs4262\\lib\\site-packages\\pandas\\core\\series.py:1111\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\chaha\\anaconda3\\envs\\cs4262\\lib\\site-packages\\pandas\\core\\series.py:1227\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1227\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\chaha\\anaconda3\\envs\\cs4262\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "first_book_title = df.iloc[0]['title']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4262",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
